## Table of Contents
   - [CoCo training](#coco-training)
       - [Pretrained CoCo Model](#pretrained-coco-model)
   - [CoCo demo](#coco-demo)
   - [DST model evaluation](#dst-model-evaluation)
       - [Classifier filter training](#classifier-filter-training)
       - [TRADE](#trade)
       - [SimpleTOD](#simpletod)
       - [TripPy](#trippy)
       - [Run Evaluation on CoCo Examples](#run-evaluation-on-coco-examples)
   - [CoCo+ as data augmentation defense](#coco-as-data-augmentation-defense)
- [License](#license)
 
### CoCo training: 
To train CoCo, run
```
sh train_coco.sh
```
After training, checkpoints are save under ```OUTPUT_DIR```, you can choose the checkpoint according to perplexity on dev set. 

#### Pretrained CoCo Model:
To use the pre-trained checkpoint used in our paper: 
1. [Download](https://storage.cloud.google.com/sfr-coco-dst-research/coco-dst-resources/coco_model.zip) and uncompress it as ```coco_model```,
2. Place the resulting ```coco_model``` folder under the current module (```coco-dst/coco-dst/```).


### CoCo demo: 
To play with controllable generation on your own input, run the following command
```
sh run_demo.sh
```
You need to modify ```eval_data_file``` and ```model_name_or_path```. For ```eval_data_file```, it's the data you want 
to run the demo on. If you wish to run demo on test set, i.e. generating dialogue turns by modifying turn-level belief 
states on test set, you can keep it as is. For ```model_name_or_path```, you can use your saved checkpoint or 
refer to [using our CoCo checkpoint](#pretrained-coco-model) if you prefer to use our checkpoint.

The demo will prompt you to input data index you want to play with where you can input an index as specified in the prompt. 
Then, you can input your modified turn-level belief state or use a default one by following the specified format in 
the prompt to generate a few candidate user utterances that can extend the conversation so far reflecting the 
user-specified belief state.   

### DST model evaluation:
#### Classifier filter training
To train the classifier filter, run
```
sh train_filter.sh
```
After training, it will save best checkpoint according to highest recall on dev set, which will be be used as part of 
filtering strategy of potentially invalid utterances generated by CoCo model. 

To use our pretrained classifier filter, 
1. [Download](https://storage.cloud.google.com/sfr-coco-dst-research/coco-dst-resources/filter.zip) and uncompress it as ```filter```,
2. Place the resulting ```filter``` folder under the ```classifier_filter``` module (```coco-dst/coco-dst/classifier_filter/```).


#### TRADE
Run
```
cd ../trade-dst
```
and open ```README.md``` for more details of ```TRADE```, including its training and how to load its checkpoints used 
in our paper.

#### SimpleTOD
Run
```
cd ../simpletod
```
and open ```README.md``` for more details of ```SimpleTOD```, including its training and how to load its checkpoints 
used in our paper.

#### TripPy
Run
```
cd ../trippy-public
```
and open ```README.md``` for more details of ```TripPy```, including its training and how to load its checkpoints 
used in our paper.

#### Run Evaluation on CoCo Examples

We define arguments of our evaluation script in the beginning of  ```main()``` method of ```run_eval.py```. There are 
several key arguments, namely ```args_target_model```, ```args_method``` , ```args_slot_value_dict``` and 
```args_slot_combination_dict``` . See the comments in the script for how to set them. This script integrates data 
generation and function calls of different models for evaluation. After setting these key arguments, run
```
sh run_eval.sh
```
Generated new user utterances after filtering and evaluation results will be saved in a ```json``` file under ```args_eval_result_save_dir+"\"+args_target_model```. Note that before evaluating the model, you need to train the target models or use the checkpoints we trained in the paper. See each folder's ```README.md``` for more details about model training and how to download corresponding checkpoints.


### CoCo+ multiple round data augmentation

We have a script ```run_gene.py``` to utilize CoCo+ as a multiple round data augmentation appraoch for retraining. 
```run_gene.py``` in current branch is slightly different from its counterpart in ```main``` branch as it supports 
for multiple round data augmentation besides single round only. ```num_aug_data``` in Line 267 of  ```run_gene.py``` 
controls the round you want to run for data augmentation.  

You can also change ```num_aug_data``` as you want and run
```
sh run_gene.sh
```
to generate additional training data by yourself. Generated data will be saved ```./coco_data``` and can be combined 
with original training data to train DST models. See ' ```README.md``` of ```TripPy``` in current branch for retraining.

OR, if you prefer to use the additional 8x training data we already generated for our experiment with ```TripPy``` 
reported in Appendix D of our paper:
1. [Download](https://storage.cloud.google.com/sfr-coco-dst-research/coco-dst-resources/coco_data.zip) and uncompress it as ```coco_data```,
2. Place the resulting ```coco_data``` folder under the current module (```coco-dst/coco-dst/```).
3. Keep the path for ```aug_file``` in ```trippy-public/train_coco-aug.sh``` as is.


## License
The code is released under BSD 3-Clause - see [LICENSE](LICENSE.txt) for details.
